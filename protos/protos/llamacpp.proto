syntax = "proto3";

package LlamaCpp;

message Void {}

message NewContextRequest {
  // TODO(crasm): model ref and context params
}

message AddTextRequest {
  Context context   = 1;
  bytes   text_utf8 = 2;
}

message TrimRequest {
  Context context = 1;
  int32   length  = 2;
}

service LlamaCpp {
  rpc NewContext(NewContextRequest) returns (Context) {};
  rpc FreeContext(Context) returns (Void);
  rpc AddText(AddTextRequest) returns (TokenList);
  rpc Trim(TrimRequest) returns (Void);
  rpc Ingest(Context) returns (Void); // TODO(crasm): return IngestProgressEvent stream
  rpc Generate(Context) returns (stream Token); // TODO(crasm): samplers
}

message Context {
  int32 id = 1;
}

message Token {
  int32 id = 1;
  optional bytes text_utf8 = 2;
}

message TokenList {
  repeated Token toks = 1;
}
