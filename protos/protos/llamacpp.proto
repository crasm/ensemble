syntax = "proto3";

package LlamaCpp;

message Void {}

message NewContextRequest {
  // TODO(crasm): model ref and context params
}

message AddTextRequest {
  Context context = 1;
  Text    text    = 2;
}

service LlamaCpp {
  rpc NewContext(NewContextRequest) returns (Context) {};
  rpc FreeContext(Context) returns (Void);
  rpc AddText(AddTextRequest) returns (TokenList);
  rpc Ingest(Context) returns (Void); // TODO(crasm): return IngestProgressEvent stream
  rpc Generate(Context) returns (stream Token); // TODO(crasm): samplers
}

message Context {
  int32 id = 1;
}

message Text {
  string text = 1;
}

message Token {
  int32 id = 1;
  optional string text = 2;
}

message TokenList {
  repeated Token toks = 1;
}
