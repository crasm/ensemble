// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint
import 'dart:ffi' as ffi;

/// FFI bindings for llama.cpp
class LlamaCpp {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
      _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  LlamaCpp(ffi.DynamicLibrary dynamicLibrary) : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  LlamaCpp.fromLookup(
      ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
          lookup)
      : _lookup = lookup;

  llama_model_params llama_model_default_params() {
    return _llama_model_default_params();
  }

  late final _llama_model_default_paramsPtr =
      _lookup<ffi.NativeFunction<llama_model_params Function()>>(
          'llama_model_default_params');
  late final _llama_model_default_params = _llama_model_default_paramsPtr
      .asFunction<llama_model_params Function()>();

  llama_context_params llama_context_default_params() {
    return _llama_context_default_params();
  }

  late final _llama_context_default_paramsPtr =
      _lookup<ffi.NativeFunction<llama_context_params Function()>>(
          'llama_context_default_params');
  late final _llama_context_default_params = _llama_context_default_paramsPtr
      .asFunction<llama_context_params Function()>();

  llama_model_quantize_params llama_model_quantize_default_params() {
    return _llama_model_quantize_default_params();
  }

  late final _llama_model_quantize_default_paramsPtr =
      _lookup<ffi.NativeFunction<llama_model_quantize_params Function()>>(
          'llama_model_quantize_default_params');
  late final _llama_model_quantize_default_params =
      _llama_model_quantize_default_paramsPtr
          .asFunction<llama_model_quantize_params Function()>();

  void llama_backend_init(
    bool numa,
  ) {
    return _llama_backend_init(
      numa,
    );
  }

  late final _llama_backend_initPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Bool)>>(
          'llama_backend_init');
  late final _llama_backend_init =
      _llama_backend_initPtr.asFunction<void Function(bool)>();

  void llama_backend_free() {
    return _llama_backend_free();
  }

  late final _llama_backend_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('llama_backend_free');
  late final _llama_backend_free =
      _llama_backend_freePtr.asFunction<void Function()>();

  ffi.Pointer<llama_model> llama_load_model_from_file(
    ffi.Pointer<ffi.Char> path_model,
    llama_model_params params,
  ) {
    return _llama_load_model_from_file(
      path_model,
      params,
    );
  }

  late final _llama_load_model_from_filePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<llama_model> Function(ffi.Pointer<ffi.Char>,
              llama_model_params)>>('llama_load_model_from_file');
  late final _llama_load_model_from_file =
      _llama_load_model_from_filePtr.asFunction<
          ffi.Pointer<llama_model> Function(
              ffi.Pointer<ffi.Char>, llama_model_params)>();

  void llama_free_model(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_free_model(
      model,
    );
  }

  late final _llama_free_modelPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_model>)>>(
          'llama_free_model');
  late final _llama_free_model = _llama_free_modelPtr
      .asFunction<void Function(ffi.Pointer<llama_model>)>();

  ffi.Pointer<llama_context> llama_new_context_with_model(
    ffi.Pointer<llama_model> model,
    llama_context_params params,
  ) {
    return _llama_new_context_with_model(
      model,
      params,
    );
  }

  late final _llama_new_context_with_modelPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<llama_context> Function(ffi.Pointer<llama_model>,
              llama_context_params)>>('llama_new_context_with_model');
  late final _llama_new_context_with_model =
      _llama_new_context_with_modelPtr.asFunction<
          ffi.Pointer<llama_context> Function(
              ffi.Pointer<llama_model>, llama_context_params)>();

  void llama_free(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_free(
      ctx,
    );
  }

  late final _llama_freePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_context>)>>(
      'llama_free');
  late final _llama_free =
      _llama_freePtr.asFunction<void Function(ffi.Pointer<llama_context>)>();

  int llama_time_us() {
    return _llama_time_us();
  }

  late final _llama_time_usPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function()>>('llama_time_us');
  late final _llama_time_us = _llama_time_usPtr.asFunction<int Function()>();

  int llama_max_devices() {
    return _llama_max_devices();
  }

  late final _llama_max_devicesPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('llama_max_devices');
  late final _llama_max_devices =
      _llama_max_devicesPtr.asFunction<int Function()>();

  bool llama_mmap_supported() {
    return _llama_mmap_supported();
  }

  late final _llama_mmap_supportedPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function()>>('llama_mmap_supported');
  late final _llama_mmap_supported =
      _llama_mmap_supportedPtr.asFunction<bool Function()>();

  bool llama_mlock_supported() {
    return _llama_mlock_supported();
  }

  late final _llama_mlock_supportedPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function()>>('llama_mlock_supported');
  late final _llama_mlock_supported =
      _llama_mlock_supportedPtr.asFunction<bool Function()>();

  ffi.Pointer<llama_model> llama_get_model(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_get_model(
      ctx,
    );
  }

  late final _llama_get_modelPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<llama_model> Function(
              ffi.Pointer<llama_context>)>>('llama_get_model');
  late final _llama_get_model = _llama_get_modelPtr.asFunction<
      ffi.Pointer<llama_model> Function(ffi.Pointer<llama_context>)>();

  int llama_n_ctx(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_n_ctx(
      ctx,
    );
  }

  late final _llama_n_ctxPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_context>)>>(
          'llama_n_ctx');
  late final _llama_n_ctx =
      _llama_n_ctxPtr.asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_vocab_type(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_vocab_type(
      model,
    );
  }

  late final _llama_vocab_typePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_model>)>>(
          'llama_vocab_type');
  late final _llama_vocab_type =
      _llama_vocab_typePtr.asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_n_vocab(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_n_vocab(
      model,
    );
  }

  late final _llama_n_vocabPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_model>)>>(
          'llama_n_vocab');
  late final _llama_n_vocab =
      _llama_n_vocabPtr.asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_n_ctx_train(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_n_ctx_train(
      model,
    );
  }

  late final _llama_n_ctx_trainPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_model>)>>(
          'llama_n_ctx_train');
  late final _llama_n_ctx_train = _llama_n_ctx_trainPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_n_embd(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_n_embd(
      model,
    );
  }

  late final _llama_n_embdPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_model>)>>(
          'llama_n_embd');
  late final _llama_n_embd =
      _llama_n_embdPtr.asFunction<int Function(ffi.Pointer<llama_model>)>();

  double llama_rope_freq_scale_train(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_rope_freq_scale_train(
      model,
    );
  }

  late final _llama_rope_freq_scale_trainPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Pointer<llama_model>)>>(
          'llama_rope_freq_scale_train');
  late final _llama_rope_freq_scale_train = _llama_rope_freq_scale_trainPtr
      .asFunction<double Function(ffi.Pointer<llama_model>)>();

  int llama_model_desc(
    ffi.Pointer<llama_model> model,
    ffi.Pointer<ffi.Char> buf,
    int buf_size,
  ) {
    return _llama_model_desc(
      model,
      buf,
      buf_size,
    );
  }

  late final _llama_model_descPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>,
              ffi.Size)>>('llama_model_desc');
  late final _llama_model_desc = _llama_model_descPtr.asFunction<
      int Function(ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>, int)>();

  int llama_model_size(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_model_size(
      model,
    );
  }

  late final _llama_model_sizePtr = _lookup<
          ffi.NativeFunction<ffi.Uint64 Function(ffi.Pointer<llama_model>)>>(
      'llama_model_size');
  late final _llama_model_size =
      _llama_model_sizePtr.asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_model_n_params(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_model_n_params(
      model,
    );
  }

  late final _llama_model_n_paramsPtr = _lookup<
          ffi.NativeFunction<ffi.Uint64 Function(ffi.Pointer<llama_model>)>>(
      'llama_model_n_params');
  late final _llama_model_n_params = _llama_model_n_paramsPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  ffi.Pointer<ggml_tensor> llama_get_model_tensor(
    ffi.Pointer<llama_model> model,
    ffi.Pointer<ffi.Char> name,
  ) {
    return _llama_get_model_tensor(
      model,
      name,
    );
  }

  late final _llama_get_model_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<llama_model>,
              ffi.Pointer<ffi.Char>)>>('llama_get_model_tensor');
  late final _llama_get_model_tensor = _llama_get_model_tensorPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>)>();

  int llama_model_quantize(
    ffi.Pointer<ffi.Char> fname_inp,
    ffi.Pointer<ffi.Char> fname_out,
    ffi.Pointer<llama_model_quantize_params> params,
  ) {
    return _llama_model_quantize(
      fname_inp,
      fname_out,
      params,
    );
  }

  late final _llama_model_quantizePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
                  ffi.Pointer<llama_model_quantize_params>)>>(
      'llama_model_quantize');
  late final _llama_model_quantize = _llama_model_quantizePtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<llama_model_quantize_params>)>();

  int llama_apply_lora_from_file(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> path_lora,
    double scale,
    ffi.Pointer<ffi.Char> path_base_model,
    int n_threads,
  ) {
    return _llama_apply_lora_from_file(
      ctx,
      path_lora,
      scale,
      path_base_model,
      n_threads,
    );
  }

  late final _llama_apply_lora_from_filePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<ffi.Char>,
              ffi.Float,
              ffi.Pointer<ffi.Char>,
              ffi.Int)>>('llama_apply_lora_from_file');
  late final _llama_apply_lora_from_file =
      _llama_apply_lora_from_filePtr.asFunction<
          int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Char>,
              double, ffi.Pointer<ffi.Char>, int)>();

  int llama_model_apply_lora_from_file(
    ffi.Pointer<llama_model> model,
    ffi.Pointer<ffi.Char> path_lora,
    double scale,
    ffi.Pointer<ffi.Char> path_base_model,
    int n_threads,
  ) {
    return _llama_model_apply_lora_from_file(
      model,
      path_lora,
      scale,
      path_base_model,
      n_threads,
    );
  }

  late final _llama_model_apply_lora_from_filePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<llama_model>,
              ffi.Pointer<ffi.Char>,
              ffi.Float,
              ffi.Pointer<ffi.Char>,
              ffi.Int)>>('llama_model_apply_lora_from_file');
  late final _llama_model_apply_lora_from_file =
      _llama_model_apply_lora_from_filePtr.asFunction<
          int Function(ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>, double,
              ffi.Pointer<ffi.Char>, int)>();

  int llama_get_kv_cache_token_count(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_get_kv_cache_token_count(
      ctx,
    );
  }

  late final _llama_get_kv_cache_token_countPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_context>)>>(
          'llama_get_kv_cache_token_count');
  late final _llama_get_kv_cache_token_count =
      _llama_get_kv_cache_token_countPtr
          .asFunction<int Function(ffi.Pointer<llama_context>)>();

  void llama_kv_cache_tokens_rm(
    ffi.Pointer<llama_context> ctx,
    int c0,
    int c1,
  ) {
    return _llama_kv_cache_tokens_rm(
      ctx,
      c0,
      c1,
    );
  }

  late final _llama_kv_cache_tokens_rmPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_context>, ffi.Int32,
              ffi.Int32)>>('llama_kv_cache_tokens_rm');
  late final _llama_kv_cache_tokens_rm = _llama_kv_cache_tokens_rmPtr
      .asFunction<void Function(ffi.Pointer<llama_context>, int, int)>();

  void llama_kv_cache_seq_rm(
    ffi.Pointer<llama_context> ctx,
    int seq_id,
    int p0,
    int p1,
  ) {
    return _llama_kv_cache_seq_rm(
      ctx,
      seq_id,
      p0,
      p1,
    );
  }

  late final _llama_kv_cache_seq_rmPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_context>, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('llama_kv_cache_seq_rm');
  late final _llama_kv_cache_seq_rm = _llama_kv_cache_seq_rmPtr
      .asFunction<void Function(ffi.Pointer<llama_context>, int, int, int)>();

  void llama_kv_cache_seq_cp(
    ffi.Pointer<llama_context> ctx,
    int seq_id_src,
    int seq_id_dst,
    int p0,
    int p1,
  ) {
    return _llama_kv_cache_seq_cp(
      ctx,
      seq_id_src,
      seq_id_dst,
      p0,
      p1,
    );
  }

  late final _llama_kv_cache_seq_cpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_context>, ffi.Int32, ffi.Int32,
              ffi.Int32, ffi.Int32)>>('llama_kv_cache_seq_cp');
  late final _llama_kv_cache_seq_cp = _llama_kv_cache_seq_cpPtr.asFunction<
      void Function(ffi.Pointer<llama_context>, int, int, int, int)>();

  void llama_kv_cache_seq_keep(
    ffi.Pointer<llama_context> ctx,
    int seq_id,
  ) {
    return _llama_kv_cache_seq_keep(
      ctx,
      seq_id,
    );
  }

  late final _llama_kv_cache_seq_keepPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_context>,
              ffi.Int32)>>('llama_kv_cache_seq_keep');
  late final _llama_kv_cache_seq_keep = _llama_kv_cache_seq_keepPtr
      .asFunction<void Function(ffi.Pointer<llama_context>, int)>();

  void llama_kv_cache_seq_shift(
    ffi.Pointer<llama_context> ctx,
    int seq_id,
    int p0,
    int p1,
    int delta,
  ) {
    return _llama_kv_cache_seq_shift(
      ctx,
      seq_id,
      p0,
      p1,
      delta,
    );
  }

  late final _llama_kv_cache_seq_shiftPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_context>, ffi.Int32, ffi.Int32,
              ffi.Int32, ffi.Int32)>>('llama_kv_cache_seq_shift');
  late final _llama_kv_cache_seq_shift =
      _llama_kv_cache_seq_shiftPtr.asFunction<
          void Function(ffi.Pointer<llama_context>, int, int, int, int)>();

  int llama_get_state_size(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_get_state_size(
      ctx,
    );
  }

  late final _llama_get_state_sizePtr = _lookup<
          ffi.NativeFunction<ffi.Size Function(ffi.Pointer<llama_context>)>>(
      'llama_get_state_size');
  late final _llama_get_state_size = _llama_get_state_sizePtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_copy_state_data(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Uint8> dst,
  ) {
    return _llama_copy_state_data(
      ctx,
      dst,
    );
  }

  late final _llama_copy_state_dataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<llama_context>,
              ffi.Pointer<ffi.Uint8>)>>('llama_copy_state_data');
  late final _llama_copy_state_data = _llama_copy_state_dataPtr.asFunction<
      int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Uint8>)>();

  int llama_set_state_data(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Uint8> src,
  ) {
    return _llama_set_state_data(
      ctx,
      src,
    );
  }

  late final _llama_set_state_dataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<llama_context>,
              ffi.Pointer<ffi.Uint8>)>>('llama_set_state_data');
  late final _llama_set_state_data = _llama_set_state_dataPtr.asFunction<
      int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Uint8>)>();

  bool llama_load_session_file(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> path_session,
    ffi.Pointer<ffi.Int32> tokens_out,
    int n_token_capacity,
    ffi.Pointer<ffi.Size> n_token_count_out,
  ) {
    return _llama_load_session_file(
      ctx,
      path_session,
      tokens_out,
      n_token_capacity,
      n_token_count_out,
    );
  }

  late final _llama_load_session_filePtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Int32>,
              ffi.Size,
              ffi.Pointer<ffi.Size>)>>('llama_load_session_file');
  late final _llama_load_session_file = _llama_load_session_filePtr.asFunction<
      bool Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Int32>, int, ffi.Pointer<ffi.Size>)>();

  bool llama_save_session_file(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> path_session,
    ffi.Pointer<ffi.Int32> tokens,
    int n_token_count,
  ) {
    return _llama_save_session_file(
      ctx,
      path_session,
      tokens,
      n_token_count,
    );
  }

  late final _llama_save_session_filePtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Int32>, ffi.Size)>>('llama_save_session_file');
  late final _llama_save_session_file = _llama_save_session_filePtr.asFunction<
      bool Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Int32>, int)>();

  int llama_eval(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Int32> tokens,
    int n_tokens,
    int n_past,
  ) {
    return _llama_eval(
      ctx,
      tokens,
      n_tokens,
      n_past,
    );
  }

  late final _llama_evalPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Int32>,
              ffi.Int32, ffi.Int)>>('llama_eval');
  late final _llama_eval = _llama_evalPtr.asFunction<
      int Function(
          ffi.Pointer<llama_context>, ffi.Pointer<ffi.Int32>, int, int)>();

  int llama_eval_embd(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Float> embd,
    int n_tokens,
    int n_past,
  ) {
    return _llama_eval_embd(
      ctx,
      embd,
      n_tokens,
      n_past,
    );
  }

  late final _llama_eval_embdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Float>,
              ffi.Int32, ffi.Int)>>('llama_eval_embd');
  late final _llama_eval_embd = _llama_eval_embdPtr.asFunction<
      int Function(
          ffi.Pointer<llama_context>, ffi.Pointer<ffi.Float>, int, int)>();

  llama_batch llama_batch_get_one(
    ffi.Pointer<ffi.Int32> tokens,
    int n_tokens,
    int pos_0,
    int seq_id,
  ) {
    return _llama_batch_get_one(
      tokens,
      n_tokens,
      pos_0,
      seq_id,
    );
  }

  late final _llama_batch_get_onePtr = _lookup<
      ffi.NativeFunction<
          llama_batch Function(ffi.Pointer<ffi.Int32>, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('llama_batch_get_one');
  late final _llama_batch_get_one = _llama_batch_get_onePtr.asFunction<
      llama_batch Function(ffi.Pointer<ffi.Int32>, int, int, int)>();

  llama_batch llama_batch_init(
    int n_tokens,
    int embd,
  ) {
    return _llama_batch_init(
      n_tokens,
      embd,
    );
  }

  late final _llama_batch_initPtr =
      _lookup<ffi.NativeFunction<llama_batch Function(ffi.Int32, ffi.Int32)>>(
          'llama_batch_init');
  late final _llama_batch_init =
      _llama_batch_initPtr.asFunction<llama_batch Function(int, int)>();

  void llama_batch_free(
    llama_batch batch,
  ) {
    return _llama_batch_free(
      batch,
    );
  }

  late final _llama_batch_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(llama_batch)>>(
          'llama_batch_free');
  late final _llama_batch_free =
      _llama_batch_freePtr.asFunction<void Function(llama_batch)>();

  int llama_decode(
    ffi.Pointer<llama_context> ctx,
    llama_batch batch,
  ) {
    return _llama_decode(
      ctx,
      batch,
    );
  }

  late final _llama_decodePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<llama_context>, llama_batch)>>('llama_decode');
  late final _llama_decode = _llama_decodePtr
      .asFunction<int Function(ffi.Pointer<llama_context>, llama_batch)>();

  void llama_set_n_threads(
    ffi.Pointer<llama_context> ctx,
    int n_threads,
    int n_threads_batch,
  ) {
    return _llama_set_n_threads(
      ctx,
      n_threads,
      n_threads_batch,
    );
  }

  late final _llama_set_n_threadsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_context>, ffi.Uint32,
              ffi.Uint32)>>('llama_set_n_threads');
  late final _llama_set_n_threads = _llama_set_n_threadsPtr
      .asFunction<void Function(ffi.Pointer<llama_context>, int, int)>();

  ffi.Pointer<ffi.Float> llama_get_logits(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_get_logits(
      ctx,
    );
  }

  late final _llama_get_logitsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(
              ffi.Pointer<llama_context>)>>('llama_get_logits');
  late final _llama_get_logits = _llama_get_logitsPtr.asFunction<
      ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>)>();

  ffi.Pointer<ffi.Float> llama_get_logits_ith(
    ffi.Pointer<llama_context> ctx,
    int i,
  ) {
    return _llama_get_logits_ith(
      ctx,
      i,
    );
  }

  late final _llama_get_logits_ithPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(
              ffi.Pointer<llama_context>, ffi.Int32)>>('llama_get_logits_ith');
  late final _llama_get_logits_ith = _llama_get_logits_ithPtr.asFunction<
      ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>, int)>();

  ffi.Pointer<ffi.Float> llama_get_embeddings(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_get_embeddings(
      ctx,
    );
  }

  late final _llama_get_embeddingsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(
              ffi.Pointer<llama_context>)>>('llama_get_embeddings');
  late final _llama_get_embeddings = _llama_get_embeddingsPtr.asFunction<
      ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>)>();

  ffi.Pointer<ffi.Char> llama_token_get_text(
    ffi.Pointer<llama_context> ctx,
    int token,
  ) {
    return _llama_token_get_text(
      ctx,
      token,
    );
  }

  late final _llama_token_get_textPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<llama_context>, ffi.Int32)>>('llama_token_get_text');
  late final _llama_token_get_text = _llama_token_get_textPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_context>, int)>();

  double llama_token_get_score(
    ffi.Pointer<llama_context> ctx,
    int token,
  ) {
    return _llama_token_get_score(
      ctx,
      token,
    );
  }

  late final _llama_token_get_scorePtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(
              ffi.Pointer<llama_context>, ffi.Int32)>>('llama_token_get_score');
  late final _llama_token_get_score = _llama_token_get_scorePtr
      .asFunction<double Function(ffi.Pointer<llama_context>, int)>();

  int llama_token_get_type(
    ffi.Pointer<llama_context> ctx,
    int token,
  ) {
    return _llama_token_get_type(
      ctx,
      token,
    );
  }

  late final _llama_token_get_typePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<llama_context>, ffi.Int32)>>('llama_token_get_type');
  late final _llama_token_get_type = _llama_token_get_typePtr
      .asFunction<int Function(ffi.Pointer<llama_context>, int)>();

  int llama_token_bos(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_token_bos(
      ctx,
    );
  }

  late final _llama_token_bosPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_context>)>>(
      'llama_token_bos');
  late final _llama_token_bos = _llama_token_bosPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_token_eos(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_token_eos(
      ctx,
    );
  }

  late final _llama_token_eosPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_context>)>>(
      'llama_token_eos');
  late final _llama_token_eos = _llama_token_eosPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_token_nl(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_token_nl(
      ctx,
    );
  }

  late final _llama_token_nlPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_context>)>>(
      'llama_token_nl');
  late final _llama_token_nl =
      _llama_token_nlPtr.asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_token_prefix(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_token_prefix(
      ctx,
    );
  }

  late final _llama_token_prefixPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_context>)>>(
      'llama_token_prefix');
  late final _llama_token_prefix = _llama_token_prefixPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_token_middle(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_token_middle(
      ctx,
    );
  }

  late final _llama_token_middlePtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_context>)>>(
      'llama_token_middle');
  late final _llama_token_middle = _llama_token_middlePtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_token_suffix(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_token_suffix(
      ctx,
    );
  }

  late final _llama_token_suffixPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_context>)>>(
      'llama_token_suffix');
  late final _llama_token_suffix = _llama_token_suffixPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_token_eot(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_token_eot(
      ctx,
    );
  }

  late final _llama_token_eotPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_context>)>>(
      'llama_token_eot');
  late final _llama_token_eot = _llama_token_eotPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_tokenize(
    ffi.Pointer<llama_model> model,
    ffi.Pointer<ffi.Char> text,
    int text_len,
    ffi.Pointer<ffi.Int32> tokens,
    int n_max_tokens,
    bool add_bos,
  ) {
    return _llama_tokenize(
      model,
      text,
      text_len,
      tokens,
      n_max_tokens,
      add_bos,
    );
  }

  late final _llama_tokenizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<llama_model>,
              ffi.Pointer<ffi.Char>,
              ffi.Int,
              ffi.Pointer<ffi.Int32>,
              ffi.Int,
              ffi.Bool)>>('llama_tokenize');
  late final _llama_tokenize = _llama_tokenizePtr.asFunction<
      int Function(ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>, int,
          ffi.Pointer<ffi.Int32>, int, bool)>();

  int llama_token_to_piece(
    ffi.Pointer<llama_model> model,
    int token,
    ffi.Pointer<ffi.Char> buf,
    int length,
  ) {
    return _llama_token_to_piece(
      model,
      token,
      buf,
      length,
    );
  }

  late final _llama_token_to_piecePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<llama_model>, ffi.Int32,
              ffi.Pointer<ffi.Char>, ffi.Int)>>('llama_token_to_piece');
  late final _llama_token_to_piece = _llama_token_to_piecePtr.asFunction<
      int Function(
          ffi.Pointer<llama_model>, int, ffi.Pointer<ffi.Char>, int)>();

  ffi.Pointer<llama_grammar> llama_grammar_init(
    ffi.Pointer<ffi.Pointer<llama_grammar_element>> rules,
    int n_rules,
    int start_rule_index,
  ) {
    return _llama_grammar_init(
      rules,
      n_rules,
      start_rule_index,
    );
  }

  late final _llama_grammar_initPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<llama_grammar> Function(
              ffi.Pointer<ffi.Pointer<llama_grammar_element>>,
              ffi.Size,
              ffi.Size)>>('llama_grammar_init');
  late final _llama_grammar_init = _llama_grammar_initPtr.asFunction<
      ffi.Pointer<llama_grammar> Function(
          ffi.Pointer<ffi.Pointer<llama_grammar_element>>, int, int)>();

  void llama_grammar_free(
    ffi.Pointer<llama_grammar> grammar,
  ) {
    return _llama_grammar_free(
      grammar,
    );
  }

  late final _llama_grammar_freePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_grammar>)>>(
      'llama_grammar_free');
  late final _llama_grammar_free = _llama_grammar_freePtr
      .asFunction<void Function(ffi.Pointer<llama_grammar>)>();

  ffi.Pointer<llama_grammar> llama_grammar_copy(
    ffi.Pointer<llama_grammar> grammar,
  ) {
    return _llama_grammar_copy(
      grammar,
    );
  }

  late final _llama_grammar_copyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<llama_grammar> Function(
              ffi.Pointer<llama_grammar>)>>('llama_grammar_copy');
  late final _llama_grammar_copy = _llama_grammar_copyPtr.asFunction<
      ffi.Pointer<llama_grammar> Function(ffi.Pointer<llama_grammar>)>();

  void llama_set_rng_seed(
    ffi.Pointer<llama_context> ctx,
    int seed,
  ) {
    return _llama_set_rng_seed(
      ctx,
      seed,
    );
  }

  late final _llama_set_rng_seedPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>, ffi.Uint32)>>('llama_set_rng_seed');
  late final _llama_set_rng_seed = _llama_set_rng_seedPtr
      .asFunction<void Function(ffi.Pointer<llama_context>, int)>();

  /// @details Repetition penalty described in CTRL academic paper https://arxiv.org/abs/1909.05858, with negative logit fix.
  void llama_sample_repetition_penalty(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    ffi.Pointer<ffi.Int32> last_tokens,
    int last_tokens_size,
    double penalty,
  ) {
    return _llama_sample_repetition_penalty(
      ctx,
      candidates,
      last_tokens,
      last_tokens_size,
      penalty,
    );
  }

  late final _llama_sample_repetition_penaltyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<ffi.Int32>,
              ffi.Size,
              ffi.Float)>>('llama_sample_repetition_penalty');
  late final _llama_sample_repetition_penalty =
      _llama_sample_repetition_penaltyPtr.asFunction<
          void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<ffi.Int32>,
              int,
              double)>();

  /// @details Frequency and presence penalties described in OpenAI API https://platform.openai.com/docs/api-reference/parameter-details.
  void llama_sample_frequency_and_presence_penalties(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    ffi.Pointer<ffi.Int32> last_tokens,
    int last_tokens_size,
    double alpha_frequency,
    double alpha_presence,
  ) {
    return _llama_sample_frequency_and_presence_penalties(
      ctx,
      candidates,
      last_tokens,
      last_tokens_size,
      alpha_frequency,
      alpha_presence,
    );
  }

  late final _llama_sample_frequency_and_presence_penaltiesPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<ffi.Int32>,
              ffi.Size,
              ffi.Float,
              ffi.Float)>>('llama_sample_frequency_and_presence_penalties');
  late final _llama_sample_frequency_and_presence_penalties =
      _llama_sample_frequency_and_presence_penaltiesPtr.asFunction<
          void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<ffi.Int32>,
              int,
              double,
              double)>();

  /// @details Apply classifier-free guidance to the logits as described in academic paper "Stay on topic with Classifier-Free Guidance" https://arxiv.org/abs/2306.17806
  /// @param candidates A vector of `llama_token_data` containing the candidate tokens, the logits must be directly extracted from the original generation context without being sorted.
  /// @params guidance_ctx A separate context from the same model. Other than a negative prompt at the beginning, it should have all generated and user input tokens copied from the main context.
  /// @params scale Guidance strength. 1.0f means no guidance. Higher values mean stronger guidance.
  void llama_sample_classifier_free_guidance(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    ffi.Pointer<llama_context> guidance_ctx,
    double scale,
  ) {
    return _llama_sample_classifier_free_guidance(
      ctx,
      candidates,
      guidance_ctx,
      scale,
    );
  }

  late final _llama_sample_classifier_free_guidancePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<llama_context>,
              ffi.Float)>>('llama_sample_classifier_free_guidance');
  late final _llama_sample_classifier_free_guidance =
      _llama_sample_classifier_free_guidancePtr.asFunction<
          void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<llama_context>,
              double)>();

  /// @details Sorts candidate tokens by their logits in descending order and calculate probabilities based on logits.
  void llama_sample_softmax(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
  ) {
    return _llama_sample_softmax(
      ctx,
      candidates,
    );
  }

  late final _llama_sample_softmaxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>)>>('llama_sample_softmax');
  late final _llama_sample_softmax = _llama_sample_softmaxPtr.asFunction<
      void Function(
          ffi.Pointer<llama_context>, ffi.Pointer<llama_token_data_array>)>();

  /// @details Top-K sampling described in academic paper "The Curious Case of Neural Text Degeneration" https://arxiv.org/abs/1904.09751
  void llama_sample_top_k(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    int k,
    int min_keep,
  ) {
    return _llama_sample_top_k(
      ctx,
      candidates,
      k,
      min_keep,
    );
  }

  late final _llama_sample_top_kPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Int,
              ffi.Size)>>('llama_sample_top_k');
  late final _llama_sample_top_k = _llama_sample_top_kPtr.asFunction<
      void Function(ffi.Pointer<llama_context>,
          ffi.Pointer<llama_token_data_array>, int, int)>();

  /// @details Nucleus sampling described in academic paper "The Curious Case of Neural Text Degeneration" https://arxiv.org/abs/1904.09751
  void llama_sample_top_p(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    double p,
    int min_keep,
  ) {
    return _llama_sample_top_p(
      ctx,
      candidates,
      p,
      min_keep,
    );
  }

  late final _llama_sample_top_pPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Float,
              ffi.Size)>>('llama_sample_top_p');
  late final _llama_sample_top_p = _llama_sample_top_pPtr.asFunction<
      void Function(ffi.Pointer<llama_context>,
          ffi.Pointer<llama_token_data_array>, double, int)>();

  /// @details Tail Free Sampling described in https://www.trentonbricken.com/Tail-Free-Sampling/.
  void llama_sample_tail_free(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    double z,
    int min_keep,
  ) {
    return _llama_sample_tail_free(
      ctx,
      candidates,
      z,
      min_keep,
    );
  }

  late final _llama_sample_tail_freePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Float,
              ffi.Size)>>('llama_sample_tail_free');
  late final _llama_sample_tail_free = _llama_sample_tail_freePtr.asFunction<
      void Function(ffi.Pointer<llama_context>,
          ffi.Pointer<llama_token_data_array>, double, int)>();

  /// @details Locally Typical Sampling implementation described in the paper https://arxiv.org/abs/2202.00666.
  void llama_sample_typical(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    double p,
    int min_keep,
  ) {
    return _llama_sample_typical(
      ctx,
      candidates,
      p,
      min_keep,
    );
  }

  late final _llama_sample_typicalPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Float,
              ffi.Size)>>('llama_sample_typical');
  late final _llama_sample_typical = _llama_sample_typicalPtr.asFunction<
      void Function(ffi.Pointer<llama_context>,
          ffi.Pointer<llama_token_data_array>, double, int)>();

  void llama_sample_temp(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    double temp,
  ) {
    return _llama_sample_temp(
      ctx,
      candidates,
      temp,
    );
  }

  late final _llama_sample_tempPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Float)>>('llama_sample_temp');
  late final _llama_sample_temp = _llama_sample_tempPtr.asFunction<
      void Function(ffi.Pointer<llama_context>,
          ffi.Pointer<llama_token_data_array>, double)>();

  void llama_sample_temperature(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    double temp,
  ) {
    return _llama_sample_temperature(
      ctx,
      candidates,
      temp,
    );
  }

  late final _llama_sample_temperaturePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Float)>>('llama_sample_temperature');
  late final _llama_sample_temperature =
      _llama_sample_temperaturePtr.asFunction<
          void Function(ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>, double)>();

  /// @details Apply constraints from grammar
  void llama_sample_grammar(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    ffi.Pointer<llama_grammar> grammar,
  ) {
    return _llama_sample_grammar(
      ctx,
      candidates,
      grammar,
    );
  }

  late final _llama_sample_grammarPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<llama_grammar>)>>('llama_sample_grammar');
  late final _llama_sample_grammar = _llama_sample_grammarPtr.asFunction<
      void Function(ffi.Pointer<llama_context>,
          ffi.Pointer<llama_token_data_array>, ffi.Pointer<llama_grammar>)>();

  /// @details Mirostat 1.0 algorithm described in the paper https://arxiv.org/abs/2007.14966. Uses tokens instead of words.
  /// @param candidates A vector of `llama_token_data` containing the candidate tokens, their probabilities (p), and log-odds (logit) for the current position in the generated text.
  /// @param tau  The target cross-entropy (or surprise) value you want to achieve for the generated text. A higher value corresponds to more surprising or less predictable text, while a lower value corresponds to less surprising or more predictable text.
  /// @param eta The learning rate used to update `mu` based on the error between the target and observed surprisal of the sampled word. A larger learning rate will cause `mu` to be updated more quickly, while a smaller learning rate will result in slower updates.
  /// @param m The number of tokens considered in the estimation of `s_hat`. This is an arbitrary value that is used to calculate `s_hat`, which in turn helps to calculate the value of `k`. In the paper, they use `m = 100`, but you can experiment with different values to see how it affects the performance of the algorithm.
  /// @param mu Maximum cross-entropy. This value is initialized to be twice the target cross-entropy (`2 * tau`) and is updated in the algorithm based on the error between the target and observed surprisal.
  int llama_sample_token_mirostat(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    double tau,
    double eta,
    int m,
    ffi.Pointer<ffi.Float> mu,
  ) {
    return _llama_sample_token_mirostat(
      ctx,
      candidates,
      tau,
      eta,
      m,
      mu,
    );
  }

  late final _llama_sample_token_mirostatPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Float,
              ffi.Float,
              ffi.Int,
              ffi.Pointer<ffi.Float>)>>('llama_sample_token_mirostat');
  late final _llama_sample_token_mirostat =
      _llama_sample_token_mirostatPtr.asFunction<
          int Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              double,
              double,
              int,
              ffi.Pointer<ffi.Float>)>();

  /// @details Mirostat 2.0 algorithm described in the paper https://arxiv.org/abs/2007.14966. Uses tokens instead of words.
  /// @param candidates A vector of `llama_token_data` containing the candidate tokens, their probabilities (p), and log-odds (logit) for the current position in the generated text.
  /// @param tau  The target cross-entropy (or surprise) value you want to achieve for the generated text. A higher value corresponds to more surprising or less predictable text, while a lower value corresponds to less surprising or more predictable text.
  /// @param eta The learning rate used to update `mu` based on the error between the target and observed surprisal of the sampled word. A larger learning rate will cause `mu` to be updated more quickly, while a smaller learning rate will result in slower updates.
  /// @param mu Maximum cross-entropy. This value is initialized to be twice the target cross-entropy (`2 * tau`) and is updated in the algorithm based on the error between the target and observed surprisal.
  int llama_sample_token_mirostat_v2(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    double tau,
    double eta,
    ffi.Pointer<ffi.Float> mu,
  ) {
    return _llama_sample_token_mirostat_v2(
      ctx,
      candidates,
      tau,
      eta,
      mu,
    );
  }

  late final _llama_sample_token_mirostat_v2Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Float,
              ffi.Float,
              ffi.Pointer<ffi.Float>)>>('llama_sample_token_mirostat_v2');
  late final _llama_sample_token_mirostat_v2 =
      _llama_sample_token_mirostat_v2Ptr.asFunction<
          int Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              double,
              double,
              ffi.Pointer<ffi.Float>)>();

  /// @details Selects the token with the highest probability.
  int llama_sample_token_greedy(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
  ) {
    return _llama_sample_token_greedy(
      ctx,
      candidates,
    );
  }

  late final _llama_sample_token_greedyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<llama_context>,
                  ffi.Pointer<llama_token_data_array>)>>(
      'llama_sample_token_greedy');
  late final _llama_sample_token_greedy =
      _llama_sample_token_greedyPtr.asFunction<
          int Function(ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>)>();

  /// @details Randomly selects a token from the candidates based on their probabilities.
  int llama_sample_token(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
  ) {
    return _llama_sample_token(
      ctx,
      candidates,
    );
  }

  late final _llama_sample_tokenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>)>>('llama_sample_token');
  late final _llama_sample_token = _llama_sample_tokenPtr.asFunction<
      int Function(
          ffi.Pointer<llama_context>, ffi.Pointer<llama_token_data_array>)>();

  /// @details Accepts the sampled token into the grammar
  void llama_grammar_accept_token(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_grammar> grammar,
    int token,
  ) {
    return _llama_grammar_accept_token(
      ctx,
      grammar,
      token,
    );
  }

  late final _llama_grammar_accept_tokenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_grammar>,
              ffi.Int32)>>('llama_grammar_accept_token');
  late final _llama_grammar_accept_token =
      _llama_grammar_accept_tokenPtr.asFunction<
          void Function(
              ffi.Pointer<llama_context>, ffi.Pointer<llama_grammar>, int)>();

  /// @details Deterministically returns entire sentence constructed by a beam search.
  /// @param ctx Pointer to the llama_context.
  /// @param callback Invoked for each iteration of the beam_search loop, passing in beams_state.
  /// @param callback_data A pointer that is simply passed back to callback.
  /// @param n_beams Number of beams to use.
  /// @param n_past Number of tokens already evaluated.
  /// @param n_predict Maximum number of tokens to predict. EOS may occur earlier.
  void llama_beam_search(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(ffi.Pointer<ffi.Void>, llama_beams_state)>>
        callback,
    ffi.Pointer<ffi.Void> callback_data,
    int n_beams,
    int n_past,
    int n_predict,
  ) {
    return _llama_beam_search(
      ctx,
      callback,
      callback_data,
      n_beams,
      n_past,
      n_predict,
    );
  }

  late final _llama_beam_searchPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<ffi.Void>, llama_beams_state)>>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Int,
              ffi.Int)>>('llama_beam_search');
  late final _llama_beam_search = _llama_beam_searchPtr.asFunction<
      void Function(
          ffi.Pointer<llama_context>,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Void Function(ffi.Pointer<ffi.Void>, llama_beams_state)>>,
          ffi.Pointer<ffi.Void>,
          int,
          int,
          int)>();

  llama_timings llama_get_timings(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_get_timings(
      ctx,
    );
  }

  late final _llama_get_timingsPtr = _lookup<
          ffi
          .NativeFunction<llama_timings Function(ffi.Pointer<llama_context>)>>(
      'llama_get_timings');
  late final _llama_get_timings = _llama_get_timingsPtr
      .asFunction<llama_timings Function(ffi.Pointer<llama_context>)>();

  void llama_print_timings(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_print_timings(
      ctx,
    );
  }

  late final _llama_print_timingsPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_context>)>>(
      'llama_print_timings');
  late final _llama_print_timings = _llama_print_timingsPtr
      .asFunction<void Function(ffi.Pointer<llama_context>)>();

  void llama_reset_timings(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_reset_timings(
      ctx,
    );
  }

  late final _llama_reset_timingsPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_context>)>>(
      'llama_reset_timings');
  late final _llama_reset_timings = _llama_reset_timingsPtr
      .asFunction<void Function(ffi.Pointer<llama_context>)>();

  ffi.Pointer<ffi.Char> llama_print_system_info() {
    return _llama_print_system_info();
  }

  late final _llama_print_system_infoPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
          'llama_print_system_info');
  late final _llama_print_system_info = _llama_print_system_infoPtr
      .asFunction<ffi.Pointer<ffi.Char> Function()>();

  void llama_log_set(
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Int32, ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Void>)>>
        log_callback,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _llama_log_set(
      log_callback,
      user_data,
    );
  }

  late final _llama_log_setPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(ffi.Int32, ffi.Pointer<ffi.Char>,
                          ffi.Pointer<ffi.Void>)>>,
              ffi.Pointer<ffi.Void>)>>('llama_log_set');
  late final _llama_log_set = _llama_log_setPtr.asFunction<
      void Function(
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Void Function(ffi.Int32, ffi.Pointer<ffi.Char>,
                      ffi.Pointer<ffi.Void>)>>,
          ffi.Pointer<ffi.Void>)>();

  void llama_dump_timing_info_yaml(
    ffi.Pointer<__sFILE> stream,
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_dump_timing_info_yaml(
      stream,
      ctx,
    );
  }

  late final _llama_dump_timing_info_yamlPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<__sFILE>,
              ffi.Pointer<llama_context>)>>('llama_dump_timing_info_yaml');
  late final _llama_dump_timing_info_yaml =
      _llama_dump_timing_info_yamlPtr.asFunction<
          void Function(ffi.Pointer<__sFILE>, ffi.Pointer<llama_context>)>();
}

final class llama_model_params extends ffi.Struct {
  @ffi.Int32()
  external int n_gpu_layers;

  @ffi.Int32()
  external int main_gpu;

  external ffi.Pointer<ffi.Float> tensor_split;

  external ffi.Pointer<
          ffi
          .NativeFunction<ffi.Void Function(ffi.Float, ffi.Pointer<ffi.Void>)>>
      progress_callback;

  external ffi.Pointer<ffi.Void> progress_callback_user_data;

  @ffi.Bool()
  external bool vocab_only;

  @ffi.Bool()
  external bool use_mmap;

  @ffi.Bool()
  external bool use_mlock;
}

final class llama_context_params extends ffi.Struct {
  @ffi.Uint32()
  external int seed;

  @ffi.Uint32()
  external int n_ctx;

  @ffi.Uint32()
  external int n_batch;

  @ffi.Uint32()
  external int n_threads;

  @ffi.Uint32()
  external int n_threads_batch;

  @ffi.Float()
  external double rope_freq_base;

  @ffi.Float()
  external double rope_freq_scale;

  @ffi.Bool()
  external bool mul_mat_q;

  @ffi.Bool()
  external bool f16_kv;

  @ffi.Bool()
  external bool logits_all;

  @ffi.Bool()
  external bool embedding;
}

final class llama_model_quantize_params extends ffi.Struct {
  @ffi.Int()
  external int nthread;

  @ffi.Int32()
  external int ftype;

  @ffi.Bool()
  external bool allow_requantize;

  @ffi.Bool()
  external bool quantize_output_tensor;

  @ffi.Bool()
  external bool only_copy;
}

abstract class llama_ftype {
  static const int LLAMA_FTYPE_ALL_F32 = 0;
  static const int LLAMA_FTYPE_MOSTLY_F16 = 1;
  static const int LLAMA_FTYPE_MOSTLY_Q4_0 = 2;
  static const int LLAMA_FTYPE_MOSTLY_Q4_1 = 3;
  static const int LLAMA_FTYPE_MOSTLY_Q4_1_SOME_F16 = 4;
  static const int LLAMA_FTYPE_MOSTLY_Q8_0 = 7;
  static const int LLAMA_FTYPE_MOSTLY_Q5_0 = 8;
  static const int LLAMA_FTYPE_MOSTLY_Q5_1 = 9;
  static const int LLAMA_FTYPE_MOSTLY_Q2_K = 10;
  static const int LLAMA_FTYPE_MOSTLY_Q3_K_S = 11;
  static const int LLAMA_FTYPE_MOSTLY_Q3_K_M = 12;
  static const int LLAMA_FTYPE_MOSTLY_Q3_K_L = 13;
  static const int LLAMA_FTYPE_MOSTLY_Q4_K_S = 14;
  static const int LLAMA_FTYPE_MOSTLY_Q4_K_M = 15;
  static const int LLAMA_FTYPE_MOSTLY_Q5_K_S = 16;
  static const int LLAMA_FTYPE_MOSTLY_Q5_K_M = 17;
  static const int LLAMA_FTYPE_MOSTLY_Q6_K = 18;
  static const int LLAMA_FTYPE_GUESSED = 1024;
}

final class llama_model extends ffi.Opaque {}

final class llama_context extends ffi.Opaque {}

abstract class llama_vocab_type1 {
  static const int LLAMA_VOCAB_TYPE_SPM = 0;
  static const int LLAMA_VOCAB_TYPE_BPE = 1;
}

final class ggml_tensor extends ffi.Struct {
  @ffi.Int32()
  external int type;

  @ffi.Int32()
  external int backend;

  external ffi.Pointer<ggml_backend_buffer> buffer;

  @ffi.Int()
  external int n_dims;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Int64> ne;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Size> nb;

  @ffi.Int32()
  external int op;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Int32> op_params;

  @ffi.Bool()
  external bool is_param;

  external ffi.Pointer<ggml_tensor> grad;

  @ffi.Array.multi([6])
  external ffi.Array<ffi.Pointer<ggml_tensor>> src;

  @ffi.Int()
  external int perf_runs;

  @ffi.Int64()
  external int perf_cycles;

  @ffi.Int64()
  external int perf_time_us;

  external ffi.Pointer<ggml_tensor> view_src;

  @ffi.Size()
  external int view_offs;

  external ffi.Pointer<ffi.Void> data;

  @ffi.Array.multi([64])
  external ffi.Array<ffi.Char> name;

  external ffi.Pointer<ffi.Void> extra;

  @ffi.Array.multi([12])
  external ffi.Array<ffi.Char> padding;
}

abstract class ggml_type {
  static const int GGML_TYPE_F32 = 0;
  static const int GGML_TYPE_F16 = 1;
  static const int GGML_TYPE_Q4_0 = 2;
  static const int GGML_TYPE_Q4_1 = 3;
  static const int GGML_TYPE_Q5_0 = 6;
  static const int GGML_TYPE_Q5_1 = 7;
  static const int GGML_TYPE_Q8_0 = 8;
  static const int GGML_TYPE_Q8_1 = 9;
  static const int GGML_TYPE_Q2_K = 10;
  static const int GGML_TYPE_Q3_K = 11;
  static const int GGML_TYPE_Q4_K = 12;
  static const int GGML_TYPE_Q5_K = 13;
  static const int GGML_TYPE_Q6_K = 14;
  static const int GGML_TYPE_Q8_K = 15;
  static const int GGML_TYPE_I8 = 16;
  static const int GGML_TYPE_I16 = 17;
  static const int GGML_TYPE_I32 = 18;
  static const int GGML_TYPE_COUNT = 19;
}

abstract class ggml_backend_type {
  static const int GGML_BACKEND_CPU = 0;
  static const int GGML_BACKEND_GPU = 10;
  static const int GGML_BACKEND_GPU_SPLIT = 20;
}

final class ggml_backend_buffer extends ffi.Opaque {}

abstract class ggml_op {
  static const int GGML_OP_NONE = 0;
  static const int GGML_OP_DUP = 1;
  static const int GGML_OP_ADD = 2;
  static const int GGML_OP_ADD1 = 3;
  static const int GGML_OP_ACC = 4;
  static const int GGML_OP_SUB = 5;
  static const int GGML_OP_MUL = 6;
  static const int GGML_OP_DIV = 7;
  static const int GGML_OP_SQR = 8;
  static const int GGML_OP_SQRT = 9;
  static const int GGML_OP_LOG = 10;
  static const int GGML_OP_SUM = 11;
  static const int GGML_OP_SUM_ROWS = 12;
  static const int GGML_OP_MEAN = 13;
  static const int GGML_OP_ARGMAX = 14;
  static const int GGML_OP_REPEAT = 15;
  static const int GGML_OP_REPEAT_BACK = 16;
  static const int GGML_OP_CONCAT = 17;
  static const int GGML_OP_SILU_BACK = 18;
  static const int GGML_OP_NORM = 19;
  static const int GGML_OP_RMS_NORM = 20;
  static const int GGML_OP_RMS_NORM_BACK = 21;
  static const int GGML_OP_GROUP_NORM = 22;
  static const int GGML_OP_MUL_MAT = 23;
  static const int GGML_OP_OUT_PROD = 24;
  static const int GGML_OP_SCALE = 25;
  static const int GGML_OP_SET = 26;
  static const int GGML_OP_CPY = 27;
  static const int GGML_OP_CONT = 28;
  static const int GGML_OP_RESHAPE = 29;
  static const int GGML_OP_VIEW = 30;
  static const int GGML_OP_PERMUTE = 31;
  static const int GGML_OP_TRANSPOSE = 32;
  static const int GGML_OP_GET_ROWS = 33;
  static const int GGML_OP_GET_ROWS_BACK = 34;
  static const int GGML_OP_DIAG = 35;
  static const int GGML_OP_DIAG_MASK_INF = 36;
  static const int GGML_OP_DIAG_MASK_ZERO = 37;
  static const int GGML_OP_SOFT_MAX = 38;
  static const int GGML_OP_SOFT_MAX_BACK = 39;
  static const int GGML_OP_ROPE = 40;
  static const int GGML_OP_ROPE_BACK = 41;
  static const int GGML_OP_ALIBI = 42;
  static const int GGML_OP_CLAMP = 43;
  static const int GGML_OP_CONV_1D = 44;
  static const int GGML_OP_CONV_2D = 45;
  static const int GGML_OP_CONV_TRANSPOSE_1D = 46;
  static const int GGML_OP_CONV_TRANSPOSE_2D = 47;
  static const int GGML_OP_POOL_1D = 48;
  static const int GGML_OP_POOL_2D = 49;
  static const int GGML_OP_CONV_1D_STAGE_0 = 50;
  static const int GGML_OP_CONV_1D_STAGE_1 = 51;
  static const int GGML_OP_UPSCALE = 52;
  static const int GGML_OP_FLASH_ATTN = 53;
  static const int GGML_OP_FLASH_FF = 54;
  static const int GGML_OP_FLASH_ATTN_BACK = 55;
  static const int GGML_OP_WIN_PART = 56;
  static const int GGML_OP_WIN_UNPART = 57;
  static const int GGML_OP_GET_REL_POS = 58;
  static const int GGML_OP_ADD_REL_POS = 59;
  static const int GGML_OP_UNARY = 60;
  static const int GGML_OP_MAP_UNARY = 61;
  static const int GGML_OP_MAP_BINARY = 62;
  static const int GGML_OP_MAP_CUSTOM1_F32 = 63;
  static const int GGML_OP_MAP_CUSTOM2_F32 = 64;
  static const int GGML_OP_MAP_CUSTOM3_F32 = 65;
  static const int GGML_OP_MAP_CUSTOM1 = 66;
  static const int GGML_OP_MAP_CUSTOM2 = 67;
  static const int GGML_OP_MAP_CUSTOM3 = 68;
  static const int GGML_OP_CROSS_ENTROPY_LOSS = 69;
  static const int GGML_OP_CROSS_ENTROPY_LOSS_BACK = 70;
  static const int GGML_OP_COUNT = 71;
}

final class llama_batch extends ffi.Struct {
  @ffi.Int32()
  external int n_tokens;

  external ffi.Pointer<ffi.Int32> token;

  external ffi.Pointer<ffi.Float> embd;

  external ffi.Pointer<ffi.Int32> pos;

  external ffi.Pointer<ffi.Int32> seq_id;

  external ffi.Pointer<ffi.Int8> logits;

  @ffi.Int32()
  external int all_pos_0;

  @ffi.Int32()
  external int all_pos_1;

  @ffi.Int32()
  external int all_seq_id;
}

abstract class llama_token_type {
  static const int LLAMA_TOKEN_TYPE_UNDEFINED = 0;
  static const int LLAMA_TOKEN_TYPE_NORMAL = 1;
  static const int LLAMA_TOKEN_TYPE_UNKNOWN = 2;
  static const int LLAMA_TOKEN_TYPE_CONTROL = 3;
  static const int LLAMA_TOKEN_TYPE_USER_DEFINED = 4;
  static const int LLAMA_TOKEN_TYPE_UNUSED = 5;
  static const int LLAMA_TOKEN_TYPE_BYTE = 6;
}

final class llama_grammar extends ffi.Opaque {}

final class llama_grammar_element extends ffi.Struct {
  @ffi.Int32()
  external int type;

  @ffi.Uint32()
  external int value;
}

abstract class llama_gretype {
  static const int LLAMA_GRETYPE_END = 0;
  static const int LLAMA_GRETYPE_ALT = 1;
  static const int LLAMA_GRETYPE_RULE_REF = 2;
  static const int LLAMA_GRETYPE_CHAR = 3;
  static const int LLAMA_GRETYPE_CHAR_NOT = 4;
  static const int LLAMA_GRETYPE_CHAR_RNG_UPPER = 5;
  static const int LLAMA_GRETYPE_CHAR_ALT = 6;
}

final class llama_token_data_array extends ffi.Struct {
  external ffi.Pointer<llama_token_data> data;

  @ffi.Size()
  external int size;

  @ffi.Bool()
  external bool sorted;
}

final class llama_token_data extends ffi.Struct {
  @ffi.Int32()
  external int id;

  @ffi.Float()
  external double logit;

  @ffi.Float()
  external double p;
}

final class llama_beams_state extends ffi.Struct {
  external ffi.Pointer<llama_beam_view> beam_views;

  @ffi.Size()
  external int n_beams;

  @ffi.Size()
  external int common_prefix_length;

  @ffi.Bool()
  external bool last_call;
}

final class llama_beam_view extends ffi.Struct {
  external ffi.Pointer<ffi.Int32> tokens;

  @ffi.Size()
  external int n_tokens;

  @ffi.Float()
  external double p;

  @ffi.Bool()
  external bool eob;
}

final class llama_timings extends ffi.Struct {
  @ffi.Double()
  external double t_start_ms;

  @ffi.Double()
  external double t_end_ms;

  @ffi.Double()
  external double t_load_ms;

  @ffi.Double()
  external double t_sample_ms;

  @ffi.Double()
  external double t_p_eval_ms;

  @ffi.Double()
  external double t_eval_ms;

  @ffi.Int32()
  external int n_sample;

  @ffi.Int32()
  external int n_p_eval;

  @ffi.Int32()
  external int n_eval;
}

abstract class ggml_log_level {
  static const int GGML_LOG_LEVEL_ERROR = 2;
  static const int GGML_LOG_LEVEL_WARN = 3;
  static const int GGML_LOG_LEVEL_INFO = 4;
}

final class __sFILE extends ffi.Struct {
  external ffi.Pointer<ffi.UnsignedChar> _p;

  @ffi.Int()
  external int _r;

  @ffi.Int()
  external int _w;

  @ffi.Short()
  external int _flags;

  @ffi.Short()
  external int _file;

  external __sbuf _bf;

  @ffi.Int()
  external int _lbfsize;

  external ffi.Pointer<ffi.Void> _cookie;

  external ffi
      .Pointer<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void>)>>
      _close;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>> _read;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.LongLong Function(
              ffi.Pointer<ffi.Void>, ffi.LongLong, ffi.Int)>> _seek;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>> _write;

  external __sbuf _ub;

  external ffi.Pointer<__sFILEX> _extra;

  @ffi.Int()
  external int _ur;

  @ffi.Array.multi([3])
  external ffi.Array<ffi.UnsignedChar> _ubuf;

  @ffi.Array.multi([1])
  external ffi.Array<ffi.UnsignedChar> _nbuf;

  external __sbuf _lb;

  @ffi.Int()
  external int _blksize;

  @ffi.LongLong()
  external int _offset;
}

final class __sbuf extends ffi.Struct {
  external ffi.Pointer<ffi.UnsignedChar> _base;

  @ffi.Int()
  external int _size;
}

final class __sFILEX extends ffi.Opaque {}
